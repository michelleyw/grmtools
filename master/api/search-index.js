var searchIndex = JSON.parse('{\
"cfgrammar":{"doc":"A library for manipulating Context Free Grammars (CFG). It …","t":[12,12,12,12,3,3,13,3,4,3,13,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,0,12,12,13,13,13,13,13,13,4,4,0,11,11,11,11,11,11,11,11,0,11,11,0,11,11,0,11,11,0,11,11,11,11,11,11,11,11,12,3,3,4,13,13,13,3,3,13,4,13,13,13,13,12,12,11,11,11,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,11,11,11,11,12,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,11,11,11,11,11,11,12,12,11,11,11,12,12,12,12,12,12,12,11,12,12,12,11,11,11,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,3,11,11,11,11,11,11,11,11,11,11,11,11,11,3,11,11,11,11,11,11,11,11,11,11,11,4,13,13,13,3,6,13,3,3,4,13,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,3,4,11,11,11,11,11,11,11,11,11,11,11,12,11,11,11,11,11,11,11],"n":["0","0","0","0","PIdx","RIdx","Rule","SIdx","Symbol","TIdx","Token","as_storaget","as_storaget","as_storaget","as_storaget","borrow","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","clone","clone","clone","clone","clone","clone_into","clone_into","clone_into","clone_into","clone_into","cmp","cmp","cmp","cmp","deserialize","deserialize","deserialize","deserialize","deserialize","eq","eq","eq","eq","eq","equivalent","equivalent","equivalent","equivalent","equivalent","fmt","fmt","fmt","fmt","fmt","from","from","from","from","from","hash","hash","hash","hash","hash","into","into","into","into","into","ne","ne","ne","ne","ne","partial_cmp","partial_cmp","partial_cmp","partial_cmp","serialize","serialize","serialize","serialize","serialize","to_owned","to_owned","to_owned","to_owned","to_owned","try_from","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","type_id","yacc","0","0","Eco","GenericParseTree","Grmtools","NoAction","Original","UserAction","YaccKind","YaccOriginalActionKind","ast","borrow","borrow","borrow_mut","borrow_mut","clone","clone","clone_into","clone_into","firsts","fmt","fmt","follows","from","from","grammar","into","into","parser","to_owned","to_owned","try_from","try_from","try_into","try_into","type_id","type_id","0","GrammarAST","GrammarValidationError","GrammarValidationErrorKind","InvalidStartRule","NoPrecForToken","NoStartRule","Production","Rule","Rule","Symbol","Token","UnknownEPP","UnknownRuleRef","UnknownToken","action","actiont","add_prod","add_programs","add_rule","avoid_insert","borrow","borrow","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","clone","clone_into","epp","eq","eq","equivalent","equivalent","expect","expectrr","fmt","fmt","fmt","fmt","fmt","fmt","fmt","from","from","from","from","from","from","get_rule","has_token","hash","implicit_tokens","into","into","into","into","into","into","kind","name","ne","ne","new","parse_param","pidxs","precedence","precs","prods","programs","rules","set_programs","start","sym","symbols","to_owned","to_string","to_string","tokens","try_from","try_from","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","type_id","type_id","0","0","YaccFirsts","borrow","borrow_mut","firsts","fmt","from","into","is_epsilon_set","is_set","new","set","try_from","try_into","type_id","YaccFollows","borrow","borrow_mut","fmt","follows","from","into","is_set","new","try_from","try_into","type_id","AssocKind","GrammarValidationError","Left","Nonassoc","Precedence","PrecedenceLevel","Right","SentenceGenerator","YaccGrammar","YaccGrammarError","YaccParserError","action","actiontype","avoid_insert","borrow","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","clone","clone","clone_into","clone_into","deserialize","deserialize","deserialize","eof_token_idx","eq","eq","expect","expectrr","firsts","fmt","fmt","fmt","fmt","follows","from","from","from","from","from","from","from","has_path","implicit_rule","into","into","into","into","into","iter_pidxs","iter_rules","iter_tidxs","kind","level","max_sentence_cost","min_sentence","min_sentence_cost","min_sentences","ne","new","new_with_storaget","parse_param","pp_prod","prod","prod_len","prod_precedence","prod_to_rule","prods_len","programs","rule_idx","rule_name","rule_to_prods","rules_len","sentence_generator","serialize","serialize","serialize","start_prod","start_rule_idx","to_owned","to_owned","to_string","token_epp","token_idx","token_name","token_precedence","tokens_len","tokens_map","try_from","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","type_id","0","0","DuplicateActiontypeDeclaration","DuplicateAvoidInsertDeclaration","DuplicateEPP","DuplicateExpectDeclaration","DuplicateExpectRRDeclaration","DuplicateImplicitTokensDeclaration","DuplicatePrecedence","DuplicateRule","DuplicateStartDeclaration","IllegalInteger","IllegalName","IllegalString","IncompleteAction","IncompleteComment","IncompleteRule","InvalidString","MismatchedBrace","MissingColon","MissingRightArrow","PrecNotFollowedByToken","PrematureEnd","ProgramsNotSupported","ReachedEOL","UnknownDeclaration","YaccParserError","YaccParserErrorKind","borrow","borrow","borrow_mut","borrow_mut","fmt","fmt","fmt","from","from","into","into","kind","to_string","try_from","try_from","try_into","try_into","type_id","type_id"],"q":["cfgrammar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","cfgrammar::Symbol","","cfgrammar::yacc","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","cfgrammar::yacc::YaccKind","cfgrammar::yacc::ast","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","cfgrammar::yacc::ast::Symbol","","cfgrammar::yacc::firsts","","","","","","","","","","","","","","cfgrammar::yacc::follows","","","","","","","","","","","","cfgrammar::yacc::grammar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","cfgrammar::yacc::grammar::YaccGrammarError","","cfgrammar::yacc::parser","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""],"d":["","","","","A type specifically for production indices (e.g. a rule …","A type specifically for rule indices.","","A type specifically for symbol indices (within a …","","A type specifically for token indices.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","The variant used in the Eco language composition editor","Automatically create a parse tree instead of …","Similar to the original Yacc style, but allowing …","Do not do execute actions of any sort.","The original Yacc style as documented by Johnson,","Execute user-specified actions attached to each …","The particular Yacc variant this grammar makes use of.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","An AST representing a grammar. This is built up gradually: …","<code>GrammarAST</code> validation errors return an instance of this …","The various different possible grammar validation errors.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","<code>Firsts</code> stores all the first sets for a given grammar. For …","","","Return all the firsts for rule <code>ridx</code>.","","","","Returns true if the rule <code>ridx</code> has epsilon in its first set.","Returns true if the token <code>tidx</code> is in the first set for …","Generates and returns the firsts set for the given grammar.","Ensures that the firsts bit for token <code>tidx</code> rule <code>ridx</code> is …","","","","<code>Follows</code> stores all the Follow sets for a given grammar. …","","","","Return the Follows <code>Vob</code> for rule <code>ridx</code>.","","","Returns true if the token <code>tidx</code> is in the follow set for …","Generates and returns the Follows set for the given …","","","","","","","","","","","A <code>SentenceGenerator</code> can generate minimal sentences for any …","Representation of a <code>YaccGrammar</code>. See the top-level …","","","Get the action for production <code>pidx</code>. Panics if <code>pidx</code> doesn’…","","Is the token <code>tidx</code> marked as <code>%avoid_insert</code>?","","","","","","","","","","","","","","","","","","Return the index of the end token.","","","","","Return a <code>YaccFirsts</code> struct for this grammar.","","","","","Return a <code>YaccFirsts</code> struct for this grammar.","","","","","","","","Is there a path from the <code>from</code> rule to the <code>to</code> rule? Note …","Return the <code>RIdx</code> of the implict rule if it exists, or <code>None</code> …","","","","","","Return an iterator which produces (in order from …","Return an iterator which produces (in order from …","Return an iterator which produces (in order from …","","","What is the cost of a maximal sentence for the rule <code>ridx</code>? …","Non-deterministically return a minimal sentence from the …","What is the cost of a minimal sentence for the rule <code>ridx</code>? …","Return (in arbitrary order) all the minimal sentences for …","","","Takes as input a Yacc grammar of <code>YaccKind</code> as a <code>String</code> <code>s</code> …","","Returns the string representation of a given production …","Get the sequence of symbols for production <code>pidx</code>. Panics if …","How many symbols does production <code>pidx</code> have? Panics if <code>pidx</code> …","Return the precedence of production <code>pidx</code> (where <code>None</code> …","Return the rule index of the production <code>pidx</code>. Panics if …","How many productions does this grammar have?","Get the programs part of the grammar","Return the index of the rule named <code>n</code> or <code>None</code> if it doesn’…","Return the name of rule <code>ridx</code>. Panics if <code>ridx</code> doesn’t …","Return the productions for rule <code>ridx</code>. Panics if <code>ridx</code> doesn…","How many rules does this grammar have?","Return a <code>SentenceGenerator</code> which can then generate minimal …","","","","Return the production index of the start rule’s sole …","What is the index of the start rule? Note that cfgrammar …","","","","Return the %epp entry for token <code>tidx</code> (where <code>None</code> indicates …","Return the index of the token named <code>n</code> or <code>None</code> if it doesn…","Return the name of token <code>tidx</code> (where <code>None</code> indicates “the …","Return the precedence of token <code>tidx</code> (where <code>None</code> indicates …","How many tokens does this grammar have?","Returns a map from names to <code>TIdx</code>s of all tokens that a …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Any error from the Yacc parser returns an instance of this …","The various different possible Yacc parser errors.","","","","","","","","","","","","","","","","","","",""],"i":[1,2,3,4,0,0,5,0,0,0,5,1,2,3,4,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,0,6,7,8,9,8,9,8,9,0,0,0,8,9,8,9,8,9,8,9,0,8,9,0,8,9,0,8,9,0,8,9,8,9,8,9,8,9,10,0,0,0,11,11,11,0,0,12,0,12,11,11,11,13,14,15,15,15,15,15,14,13,12,11,16,15,14,13,12,11,16,12,12,15,13,12,13,12,15,15,14,13,12,12,11,16,16,15,14,13,12,11,16,15,15,12,15,15,14,13,12,11,16,16,14,13,12,15,15,14,13,15,15,15,15,15,15,16,13,12,12,16,15,15,14,13,12,11,16,15,14,13,12,11,16,15,14,13,12,11,16,17,18,0,19,19,19,19,19,19,19,19,19,19,19,19,19,0,20,20,20,20,20,20,20,20,20,20,20,0,21,22,22,0,0,22,0,0,0,21,23,23,23,24,25,22,23,21,24,25,22,23,21,25,22,25,22,25,22,23,23,25,22,23,23,23,25,22,21,21,23,24,25,22,23,21,21,21,23,23,24,25,22,23,21,23,23,23,25,25,24,24,24,24,25,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,25,22,23,23,23,25,22,21,23,23,23,23,23,23,24,25,22,23,21,24,25,22,23,21,24,25,22,23,21,26,27,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,0,0,28,29,28,29,28,29,29,28,29,28,29,29,29,28,29,28,29,28,29],"f":[null,null,null,null,null,null,null,null,null,null,null,[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["ridx",3]],[[],["pidx",3]],[[],["sidx",3]],[[],["tidx",3]],[[],["symbol",4]],[[]],[[]],[[]],[[]],[[]],[[["ridx",3]],["ordering",4]],[[["pidx",3]],["ordering",4]],[[["sidx",3]],["ordering",4]],[[["tidx",3]],["ordering",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[["ridx",3]],["bool",15]],[[["pidx",3]],["bool",15]],[[["sidx",3]],["bool",15]],[[["tidx",3]],["bool",15]],[[["symbol",4]],["bool",15]],[[],["bool",15]],[[],["bool",15]],[[],["bool",15]],[[],["bool",15]],[[],["bool",15]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[["ridx",3]],["bool",15]],[[["pidx",3]],["bool",15]],[[["sidx",3]],["bool",15]],[[["tidx",3]],["bool",15]],[[["symbol",4]],["bool",15]],[[["ridx",3]],["option",4,[["ordering",4]]]],[[["pidx",3]],["option",4,[["ordering",4]]]],[[["sidx",3]],["option",4,[["ordering",4]]]],[[["tidx",3]],["option",4,[["ordering",4]]]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[]],[[]],[[]],[[]],[[]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],null,null,null,null,null,null,null,null,null,null,null,null,[[]],[[]],[[]],[[]],[[],["yacckind",4]],[[],["yaccoriginalactionkind",4]],[[]],[[]],null,[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],null,[[]],[[]],null,[[]],[[]],null,[[]],[[]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],[[],["typeid",3]],null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,[[["string",3],["vec",3,[["symbol",4]]],["option",4,[["string",3]]],["option",4,[["string",3]]]]],[[["string",3]]],[[["string",3],["option",4,[["string",3]]]]],null,[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["symbol",4]],[[]],null,[[["production",3]],["bool",15]],[[["symbol",4]],["bool",15]],[[],["bool",15]],[[],["bool",15]],null,null,[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[]],[[]],[[]],[[]],[[]],[[]],[[["str",15]],["option",4,[["rule",3]]]],[[["str",15]],["bool",15]],[[]],null,[[]],[[]],[[]],[[]],[[]],[[]],null,null,[[["production",3]],["bool",15]],[[["symbol",4]],["bool",15]],[[],["grammarast",3]],null,null,null,null,null,null,null,[[["string",3]]],null,null,null,[[]],[[],["string",3]],[[],["string",3]],null,[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],null,null,null,[[]],[[]],[[["ridx",3]],["vob",3]],[[["formatter",3]],["result",6]],[[]],[[]],[[["ridx",3]],["bool",15]],[[["ridx",3],["tidx",3]],["bool",15]],[[["yaccgrammar",3]]],[[["ridx",3],["tidx",3]],["bool",15]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],null,[[]],[[]],[[["formatter",3]],["result",6]],[[["ridx",3]],["vob",3]],[[]],[[]],[[["ridx",3],["tidx",3]],["bool",15]],[[["yaccgrammar",3]]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],null,null,null,null,null,null,null,null,null,null,null,[[["pidx",3]],["option",4]],[[["ridx",3]],["option",4]],[[["tidx",3]],["bool",15]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["precedence",3]],[[],["assockind",4]],[[]],[[]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["tidx",3]],[[["precedence",3]],["bool",15]],[[["assockind",4]],["bool",15]],[[],["option",4,[["usize",15]]]],[[],["option",4,[["usize",15]]]],[[],["yaccfirsts",3]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[],["yaccfollows",3]],[[]],[[]],[[]],[[]],[[["grammarvalidationerror",3]],["yaccgrammarerror",4]],[[]],[[["yaccparsererror",3]],["yaccgrammarerror",4]],[[["ridx",3],["ridx",3]],["bool",15]],[[],["option",4,[["ridx",3]]]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],null,null,[[["ridx",3]],["option",4,[["u16",15]]]],[[["ridx",3]],["vec",3,[["tidx",3]]]],[[["ridx",3]],["u16",15]],[[["ridx",3]],["vec",3,[["vec",3,[["tidx",3]]]]]],[[["precedence",3]],["bool",15]],[[["yacckind",4],["str",15]],["result",4,[["yaccgrammarerror",4]]]],[[["yacckind",4],["str",15]],["result",4,[["yaccgrammarerror",4]]]],[[],["option",4]],[[["pidx",3]],["string",3]],[[["pidx",3]]],[[["pidx",3]],["sidx",3]],[[["pidx",3]],["option",4,[["precedence",3]]]],[[["pidx",3]],["ridx",3]],[[],["pidx",3]],[[],["option",4]],[[["str",15]],["option",4,[["ridx",3]]]],[[["ridx",3]],["str",15]],[[["ridx",3]]],[[],["ridx",3]],[[],["sentencegenerator",3]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["pidx",3]],[[],["ridx",3]],[[]],[[]],[[],["string",3]],[[["tidx",3]],["option",4,[["str",15]]]],[[["str",15]],["option",4,[["tidx",3]]]],[[["tidx",3]],["option",4,[["str",15]]]],[[["tidx",3]],["option",4,[["precedence",3]]]],[[],["tidx",3]],[[],["hashmap",3,[["str",15],["tidx",3]]]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,[[]],[[]],[[]],[[]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[]],[[]],[[]],[[]],null,[[],["string",3]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],[[],["typeid",3]]],"p":[[3,"RIdx"],[3,"PIdx"],[3,"SIdx"],[3,"TIdx"],[4,"Symbol"],[13,"Rule"],[13,"Token"],[4,"YaccKind"],[4,"YaccOriginalActionKind"],[13,"Original"],[4,"GrammarValidationErrorKind"],[4,"Symbol"],[3,"Production"],[3,"Rule"],[3,"GrammarAST"],[3,"GrammarValidationError"],[13,"Rule"],[13,"Token"],[3,"YaccFirsts"],[3,"YaccFollows"],[4,"YaccGrammarError"],[4,"AssocKind"],[3,"YaccGrammar"],[3,"SentenceGenerator"],[3,"Precedence"],[13,"YaccParserError"],[13,"GrammarValidationError"],[4,"YaccParserErrorKind"],[3,"YaccParserError"]]},\
"lrlex":{"doc":"<code>lrlex</code> is a partial replacement for <code>lex</code> / <code>flex</code>. It takes in …","t":[3,3,3,13,13,3,13,3,3,6,4,6,8,4,13,6,13,13,13,13,13,13,13,13,13,13,4,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,5,11,11,11,11,5,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,10,11,10,11,10,11,10,11,11,11,11,11,11,11,11,11,11,11,11,10,11,12,11,11,11,11,11,14,11,11,11,11,11,11,11,11,11,11,11,11,11,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12],"n":["CTLexer","CTLexerBuilder","DefaultLexeme","DuplicateName","InvalidName","LRNonStreamingLexer","LRNonStreamingLexer","LRNonStreamingLexerDef","LexBuildError","LexBuildResult","LexErrorKind","LexerBuilder","LexerDef","LexerKind","MissingSpace","NonStreamingLexerDef","PrematureEnd","Private","Public","PublicCrate","PublicIn","PublicSelf","PublicSuper","RegexError","RoutinesNotSupported","UnknownDeclaration","Visibility","allow_missing_terms_in_lexer","allow_missing_tokens_in_parser","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","build","build_lex","clone","clone","clone_into","clone_into","ct_token_map","eq","eq","equivalent","equivalent","faulty","fmt","fmt","fmt","fmt","fmt","fmt","from","from","from","from","from","from","from","from","from","from_str","from_str","get_rule","get_rule","get_rule_by_id","get_rule_by_id","get_rule_by_name","get_rule_by_name","hash","into","into","into","into","into","into","into","into","into","iter","iter_rules","iter_rules","kind","lexer","lexer_in_src_dir","lexer_path","lexerkind","line_col","lrlex_mod","lrpar_config","mod_name","ne","ne","new","new","new","new_faulty","new_with_lexemet","output_path","process_file","process_file_in_src","rule_ids_map","set_rule_ids","set_rule_ids","span","span_lines_str","span_str","to_owned","to_owned","to_string","to_string","tok_id","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","visibility","0"],"q":["lrlex","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","lrlex::Visibility"],"d":["An interface to the result of CTLexerBuilder::build().","A <code>CTLexerBuilder</code> allows one to specify the criteria for …","lrlex’s standard lexeme struct: all lexemes are …","","","An <code>LRNonStreamingLexer</code> holds a reference to a string and …","","This struct represents, in essence, a .l file in memory. …","Any error from the Lex parser returns an instance of this …","","The various different possible Lex parser errors.","","Methods which all lexer definitions must implement.","","","","","Module-level visibility only.","<code>pub</code>","<code>pub(crate)</code>","<code>pub(in {arg})</code>","<code>pub(self)</code>","<code>pub(super)</code>","","","","Specify the visibility of the module generated by …","If passed false, tokens used in the grammar but not …","If passed false, tokens defined in the lexer but not used …","","","","","","","","","","","","","","","","","","","Statically compile the <code>.l</code> file specified by …","","","","","","Create a Rust module named <code>mod_name</code> that can be imported …","","","","","","","","","","","","","","","","","","","","","Instantiate a lexer from a string (e.g. representing a <code>.l</code> …","","Get the <code>Rule</code> at index <code>idx</code>.","","Get the <code>Rule</code> instance associated with a particular lexeme …","","Get the <code>Rule</code> instance associated with a particular name.","","","","","","","","","","","","","Returns an iterator over all rules in this AST.","","","Return an LRNonStreamingLexer for the <code>String</code> <code>s</code> that will …","Set the input lexer path to a file relative to this project…","Set the input lexer path to <code>inp</code>. If specified, you must …","Set the type of lexer to be generated to <code>lexerkind</code>.","","A convenience macro for including statically compiled <code>.l</code> …","An optional convenience function to make it easier to …","Set the generated module name to <code>mod_name</code>. If no module …","","","Create a new CTLexerBuilder.","Create a new <code>LRNonStreamingLexer</code> that read in: the input <code>s</code>…","","","Create a new CTLexerBuilder.","Set the output lexer path to <code>outp</code>. Note that there are no …","Statically compile the <code>.l</code> file <code>inp</code> into Rust, placing the …","Given the filename <code>a/b.l</code> as input, statically compile the …","Set this lexer builder’s map of rule IDs to <code>rule_ids_map</code>…","Set the id attribute on rules to the corresponding value …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Set the visibility of the generated module to <code>vis</code>. …",""],"i":[0,0,0,1,1,0,2,0,0,0,0,0,0,0,1,0,1,3,3,3,3,3,3,1,1,1,0,4,4,2,4,5,6,7,3,8,9,1,2,4,5,6,7,3,8,9,1,4,0,3,8,3,8,0,3,8,3,8,8,3,8,8,9,9,1,2,4,5,6,7,3,8,9,1,10,6,10,6,10,6,10,6,8,2,4,5,6,7,3,8,9,1,7,10,6,9,6,4,4,4,7,0,4,4,3,8,4,7,8,8,4,4,4,4,4,10,6,8,7,7,3,8,8,9,8,2,4,5,6,7,3,8,9,1,2,2,4,4,5,5,6,6,7,7,3,3,8,8,9,9,1,1,2,4,5,6,7,3,8,9,1,4,11],"f":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,[[["bool",15]]],[[["bool",15]]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["result",4,[["ctlexer",3],["box",3,[["error",8]]]]]],[[["str",15]],["result",4,[["lrnonstreaminglexerdef",3,[["lexeme",8,[["",26,[["copy",8],["eq",8],["hash",8],["primint",8],["tryfrom",8,[["usize",15]]],["unsigned",8]]]]],["",26,[["copy",8],["eq",8],["hash",8],["primint",8],["tryfrom",8,[["usize",15]]],["unsigned",8]]]]],["lexbuilderror",3]]]],[[],["visibility",4]],[[],["defaultlexeme",3]],[[]],[[]],[[["str",15],["hashmap",3],["option",4,[["hashmap",3]]]],["result",4,[["box",3,[["error",8]]]]]],[[["visibility",4]],["bool",15]],[[["defaultlexeme",3]],["bool",15]],[[],["bool",15]],[[],["bool",15]],[[],["bool",15]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[["str",15]],["lexbuildresult",6]],[[["str",15]],["lexbuildresult",6,[["lrnonstreaminglexerdef",3]]]],[[["usize",15]],["option",4,[["rule",3]]]],[[["usize",15]],["option",4,[["rule",3]]]],[[],["rule",3]],[[],["rule",3]],[[["str",15]],["option",4,[["rule",3]]]],[[["str",15]],["option",4,[["rule",3]]]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["box",3,[["iterator",8]]]],[[],["iter",3,[["rule",3]]]],[[],["iter",3,[["rule",3]]]],null,[[["str",15]],["lrnonstreaminglexer",3]],[[],["result",4,[["box",3,[["error",8]]]]]],[[]],[[["lexerkind",4]]],[[["span",3]]],null,[[]],[[["str",15]]],[[["visibility",4]],["bool",15]],[[["defaultlexeme",3]],["bool",15]],[[]],[[["str",15],["vec",3,[["result",4,[["lexerror",3]]]]],["vec",3,[["usize",15]]]],["lrnonstreaminglexer",3]],[[["usize",15],["usize",15]]],[[["usize",15],["usize",15]]],[[]],[[]],[[],["result",4,[["box",3,[["error",8]]]]]],[[["str",15]],["result",4,[["box",3,[["error",8]]]]]],[[["",26,[["borrow",8,[["hashmap",3,[["string",3]]]]],["clone",8]]]]],[[["hashmap",3]]],[[["hashmap",3]]],[[],["span",3]],[[["span",3]],["str",15]],[[["span",3]],["str",15]],[[]],[[]],[[],["string",3]],[[],["string",3]],[[]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[["visibility",4]]],null],"p":[[4,"LexErrorKind"],[4,"LexerKind"],[4,"Visibility"],[3,"CTLexerBuilder"],[3,"CTLexer"],[3,"LRNonStreamingLexerDef"],[3,"LRNonStreamingLexer"],[3,"DefaultLexeme"],[3,"LexBuildError"],[8,"LexerDef"],[13,"PublicIn"]]},\
"lrpar":{"doc":"<code>lrpar</code> provides a Yacc-compatible parser (where grammars …","t":[13,3,3,13,13,3,13,4,8,8,4,8,13,13,3,13,4,13,13,13,13,13,13,3,4,13,3,13,4,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,10,11,11,10,14,11,11,11,11,11,11,10,11,11,11,11,10,11,11,11,11,11,11,11,11,11,11,11,11,10,11,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12],"n":["CPCTPlus","CTParser","CTParserBuilder","Delete","Insert","LexError","LexError","LexParseError","Lexeme","Lexer","Node","NonStreamingLexer","None","Nonterm","ParseError","ParseError","ParseRepair","Private","Public","PublicCrate","PublicIn","PublicSelf","PublicSuper","RTParserBuilder","RecoveryKind","Shift","Span","Term","Visibility","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","build","clone","clone","clone","clone","clone","clone","clone","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","conflicts","end","eq","eq","eq","eq","eq","equivalent","equivalent","equivalent","error_on_conflicts","faulty","fmt","fmt","fmt","fmt","fmt","fmt","fmt","fmt","fmt","fmt","fmt","from","from","from","from","from","from","from","from","from","from","from","from","from","grammar_in_src_dir","grammar_path","hash","into","into","into","into","into","into","into","into","into","into","into","is_empty","iter","len","lexeme","line_col","lrpar_mod","mod_name","ne","ne","ne","ne","ne","new","new","new","new","new","new_faulty","output_path","parse_actions","parse_generictree","parse_noaction","pp","pp","process_file","process_file_in_src","recoverer","recoverer","regenerated","repairs","span","span","span_lines_str","span_str","start","stidx","term_costs","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","to_string","to_string","to_string","tok_id","token_map","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","visibility","yacckind","0","0","lexeme","nodes","ridx","0","0","0","0"],"q":["lrpar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","lrpar::LexParseError","","lrpar::Node","","","lrpar::ParseRepair","","","lrpar::Visibility"],"d":["The CPCT+ algorithm from Diekmann/Tratt “Don’t Panic! …","An interface to the result of CTParserBuilder::build().","A <code>CTParserBuilder</code> allows one to specify the criteria for …","Delete a symbol.","Insert a <code>Symbol::Token</code>.","A Lexing error.","","A lexing or parsing error. Although the two are quite …","A lexeme represents a segment of the user’s input that …","The base trait which all lexers which want to interact …","A generic parse tree.","A <code>NonStreamingLexer</code> is one that takes input in one go, and …","Don’t use error recovery: return as soon as the first …","Nonterminals reference a rule and have zero or more <code>Node</code>s …","Records a single parse error.","","After a parse error is encountered, the parser attempts to …","Module-level visibility only.","<code>pub</code>","<code>pub(crate)</code>","<code>pub(in {arg})</code>","<code>pub(self)</code>","<code>pub(super)</code>","A run-time parser builder.","What recovery algorithm should be used when a syntax error …","Shift a symbol.","A <code>Span</code> records what portion of the user’s input …","Terminals store a single lexeme.","Specify the visibility of the module generated by <code>CTBuilder</code>…","","","","","","","","","","","","","","","","","","","","","","","Statically compile the Yacc file specified by …","","","","","","","","","","","","","","","If there are any conflicts in the grammar, return a tuple …","Byte offset of the end of the span.","","","","","","","","","If set to true, CTParserBuilder::build will return an …","Returns <code>true</code> if this lexeme is “faulty” i.e. is the …","","","","","","","","","","","","","","","","","","","","","","","","","Set the input grammar path to a file relative to this …","Set the input grammar path to <code>inp</code>. If specified, you must …","","","","","","","","","","","","","Returns <code>true</code> if this <code>Span</code> covers 0 bytes, or <code>false</code> …","Iterate over all the lexemes in this lexer. Note that:","Length in bytes of the span.","Return the lexeme where this error was detected.","Return <code>((start line, start column), (end line, end column))</code>…","A convenience macro for including statically compiled <code>.y</code> …","Set the generated module name to <code>mod_name</code>. If no module …","","","","","","Create a new lexeme with ID <code>tok_id</code>, a starting position in …","Create a new <code>CTParserBuilder</code>.","Create a new run-time parser from a <code>YaccGrammar</code>, a …","","Create a new span starting at byte <code>start</code> and ending at …","Create a new faulty lexeme with ID <code>tok_id</code> and a starting …","Set the output grammar path to <code>outp</code>. Note that there are …","Parse input, execute actions, and return the associated …","Parse input, and (if possible) return a generic parse …","Parse input, returning any errors found. See the arguments …","Return a pretty-printed version of this node.","A pretty-printer of a lexer/parser error. This isn’t …","Statically compile the Yacc file <code>inp</code> into Rust, placing …","Given the filename <code>a/b.y</code> as input, statically compile the …","Set the recoverer for this parser to <code>rk</code>. Defaults to …","Set the recoverer for this parser to <code>rk</code>.","Returns <code>true</code> if this compile-time parser was regenerated …","Return the repairs found that would fix this error. Note …","Obtain this <code>Lexeme</code>’s Span.","","Return the lines containing the input at <code>span</code> (including …","Return the user input associated with a Span.","Byte offset of the start of the span.","Return the state table index where this error was detected.","","","","","","","","","","","","The token ID.","Returns a HashMap from lexeme string types to numeric …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Set the visibility of the generated module to <code>vis</code>. …","Set the <code>YaccKind</code> for this parser to <code>ak</code>.","","","","","","","","",""],"i":[1,0,0,2,2,0,3,0,0,0,0,0,1,4,0,3,0,5,5,5,5,5,5,0,0,2,0,4,0,6,7,8,5,9,4,1,3,2,10,11,6,7,8,5,9,4,1,3,2,10,11,6,5,9,4,1,2,10,11,5,9,4,1,2,10,11,7,11,5,4,2,10,11,5,2,11,6,12,5,9,9,4,1,3,3,2,10,10,11,6,7,8,5,9,4,1,3,3,3,2,10,11,6,6,2,6,7,8,5,9,4,1,3,2,10,11,11,13,11,10,14,0,6,5,4,2,10,11,12,6,8,9,11,12,6,8,8,8,4,3,6,6,6,8,7,10,12,9,14,14,11,10,8,5,9,4,1,2,10,11,9,3,10,12,7,6,7,8,5,9,4,1,3,2,10,11,6,6,7,7,8,8,5,5,9,9,4,4,1,1,3,3,2,2,10,10,11,11,6,7,8,5,9,4,1,3,2,10,11,6,6,15,16,17,18,18,19,20,21,22],"f":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["result",4,[["ctparser",3],["box",3,[["error",8]]]]]],[[],["visibility",4]],[[],["lexerror",3]],[[],["node",4]],[[],["recoverykind",4]],[[],["parserepair",4]],[[],["parseerror",3]],[[],["span",3]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["option",4]],[[],["usize",15]],[[["visibility",4]],["bool",15]],[[["node",4]],["bool",15]],[[["parserepair",4]],["bool",15]],[[["parseerror",3]],["bool",15]],[[["span",3]],["bool",15]],[[],["bool",15]],[[],["bool",15]],[[],["bool",15]],[[["bool",15]]],[[],["bool",15]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[["lexerror",3]],["lexparseerror",4]],[[]],[[["parseerror",3]],["lexparseerror",4]],[[]],[[]],[[]],[[],["result",4,[["box",3,[["error",8]]]]]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["bool",15]],[[],["box",3,[["iterator",8]]]],[[],["usize",15]],[[]],[[["span",3]]],null,[[["str",15]]],[[["visibility",4]],["bool",15]],[[["node",4]],["bool",15]],[[["parserepair",4]],["bool",15]],[[["parseerror",3]],["bool",15]],[[["span",3]],["bool",15]],[[["usize",15],["usize",15]]],[[]],[[["yaccgrammar",3],["statetable",3]]],[[["span",3]]],[[["usize",15],["usize",15]]],[[["usize",15],["usize",15]]],[[]],[[["nonstreaminglexer",8],["copy",8]]],[[["nonstreaminglexer",8]]],[[["nonstreaminglexer",8]],["vec",3,[["lexparseerror",4]]]],[[["yaccgrammar",3],["str",15]],["string",3]],[[["nonstreaminglexer",8],["fn",8]],["string",3]],[[],["result",4,[["hashmap",3,[["string",3]]],["box",3,[["error",8]]]]]],[[["str",15]],["result",4,[["hashmap",3,[["string",3]]],["box",3,[["error",8]]]]]],[[["recoverykind",4]]],[[["recoverykind",4]]],[[],["bool",15]],[[],["vec",3]],[[],["span",3]],[[],["span",3]],[[["span",3]],["str",15]],[[["span",3]],["str",15]],[[],["usize",15]],[[],["stidx",3]],[[["fn",8]]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["string",3]],[[],["string",3]],[[],["string",3]],[[]],[[],["hashmap",3]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[["visibility",4]]],[[["yacckind",4]]],null,null,null,null,null,null,null,null,null],"p":[[4,"RecoveryKind"],[4,"ParseRepair"],[4,"LexParseError"],[4,"Node"],[4,"Visibility"],[3,"CTParserBuilder"],[3,"CTParser"],[3,"RTParserBuilder"],[3,"LexError"],[3,"ParseError"],[3,"Span"],[8,"Lexeme"],[8,"Lexer"],[8,"NonStreamingLexer"],[13,"LexError"],[13,"ParseError"],[13,"Term"],[13,"Nonterm"],[13,"Insert"],[13,"Delete"],[13,"Shift"],[13,"PublicIn"]]},\
"lrpar_tests":{"doc":"","t":[],"n":[],"q":[],"d":[],"i":[],"f":[],"p":[]},\
"lrtable":{"doc":"","t":[4,13,3,6,3,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,5,11,11,11,11,11,11,11,11,11,11,11,11,11,0,11,11,11,11,11,11,11,11,11,11,11,11,11,11,13,13,4,3,3,13,13,13,3,3,3,4,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,11,11,11,11,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12],"n":["Minimiser","Pager","StIdx","StIdxStorageT","StateGraph","all_edges_len","all_states_len","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","clone","clone","clone_into","clone_into","closed_state","core_state","deserialize","edge","edges","eq","equivalent","fmt","fmt","from","from","from","from","from","from_yacc","hash","into","into","into","iter_closed_states","iter_core_states","iter_stidxs","ne","pp","pp_closed_states","pp_core_states","serialize","start_state","statetable","to_owned","to_owned","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","Accept","AcceptReduceConflict","Action","Conflicts","CoreReducesIterator","Error","Reduce","Shift","StateActionsIterator","StateTable","StateTableError","StateTableErrorKind","action","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","clone","clone_into","conflicts","core_reduces","deserialize","deserialize","deserialize","eq","fmt","fmt","fmt","fmt","fmt","from","from","from","from","from","from","from","goto","into","into","into","into","into","into","into","into_iter","into_iter","kind","ne","new","next","next","pidx","pp","pp_rr","pp_sr","reduce_only_state","rr_conflicts","rr_len","serialize","serialize","serialize","sr_conflicts","sr_len","start_state","state_actions","state_shifts","to_owned","to_string","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","type_id","type_id","type_id","0","0"],"q":["lrtable","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","lrtable::statetable","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","lrtable::statetable::Action",""],"d":["","","StIdx is a wrapper for a state index. Its internal type is …","The type of the inner value of an StIdx.","","How many edges does this <code>StateGraph</code> contain?","How many states does this <code>StateGraph</code> contain? NB: By …","","","","","","","","","","","Return the itemset for closed state <code>stidx</code>. Panics if <code>stidx</code> …","Return the itemset for core state <code>stidx</code> or <code>None</code> if it doesn…","","Return the state pointed to by <code>sym</code> from <code>stidx</code> or <code>None</code> …","Return the edges for state <code>stidx</code>. Panics if <code>stidx</code> doesn’…","","","","","","","","","","","","","","","Return an iterator over all closed states in this …","Return an iterator over all core states in this <code>StateGraph</code>.","Return an iterator which produces (in order from …","","Pretty print this stategraph as a <code>String</code>. If <code>core_states</code> …","Return a pretty printed version of the closed states, and …","Return a pretty printed version of the core states, and …","","Return this state graph’s start state.","","","","","","","","","","","","","","","","Accept this input.","","","","","No valid action.","Reduce production X in the grammar.","Shift to state X in the statetable.","","A representation of a <code>StateTable</code> for a grammar. <code>actions</code> …","Any error from the Yacc parser returns an instance of this …","The various different possible Yacc parser errors.","Return the action for <code>stidx</code> and <code>sym</code>, or <code>None</code> if there isn…","","","","","","","","","","","","","","","","","Return a struct containing all conflicts or <code>None</code> if there …","Return an iterator over a set of “core” reduces of …","","","","","","","","","","","","","","","","","Return the goto state for <code>stidx</code> and <code>ridx</code>, or <code>None</code> if there …","","","","","","","","","","","","","","","","Returns a pretty-printed version of the conflicts.","Returns a pretty-printed version of the reduce/reduce …","Returns a pretty-printed version of the shift/reduce …","Does the state <code>stidx</code> 1) only contain reduce (and error) …","Return an iterator over all reduce/reduce conflicts.","How many reduce/reduce conflicts are there?","","","","Return an iterator over all shift/reduce conflicts.","How many shift/reduce conflicts are there?","Return this state table’s start state.","Return an iterator over the indexes of all non-empty …","Return an iterator over the indexes of all shift actions …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""],"i":[0,1,0,0,0,2,2,2,3,1,2,3,1,3,1,3,1,2,2,3,2,2,3,3,2,3,4,2,3,3,1,0,3,2,3,1,2,2,2,3,2,2,2,3,2,0,3,1,2,3,1,2,2,3,3,1,1,2,3,1,5,6,0,0,0,5,5,5,0,0,0,0,7,8,9,10,6,11,7,5,8,9,10,6,11,7,5,5,5,7,7,10,7,5,5,10,6,11,11,5,8,9,10,6,11,7,5,7,8,9,10,6,11,7,5,8,9,11,5,7,8,9,11,10,10,10,7,10,10,10,7,5,10,10,7,7,7,5,11,8,9,10,6,11,7,5,8,8,9,9,10,10,6,6,11,11,7,7,5,5,8,9,10,6,11,7,5,12,13],"f":[null,null,null,null,null,[[],["usize",15]],[[],["stidx",3]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["stidx",3]],[[],["minimiser",4]],[[]],[[]],[[["stidx",3]],["itemset",3]],[[["stidx",3]],["itemset",3]],[[],["result",4]],[[["stidx",3],["symbol",4]],["option",4,[["stidx",3]]]],[[["stidx",3]],["hashmap",3]],[[["stidx",3]],["bool",15]],[[],["bool",15]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["stidx",3]]],[[]],[[["stidxstoraget",6]]],[[]],[[]],[[["yaccgrammar",3],["minimiser",4]],["result",4,[["statetableerror",3,[["",26,[["hash",8],["primint",8],["unsigned",8]]]]]]]],[[]],[[]],[[]],[[]],[[],["box",3,[["iterator",8]]]],[[],["box",3,[["iterator",8]]]],[[],["box",3,[["iterator",8]]]],[[["stidx",3]],["bool",15]],[[["yaccgrammar",3],["bool",15]],["string",3]],[[["yaccgrammar",3]],["string",3]],[[["yaccgrammar",3]],["string",3]],[[],["result",4]],[[],["stidx",3]],null,[[]],[[]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],null,null,null,null,null,null,null,null,null,null,null,null,[[["stidx",3],["tidx",3]],["action",4]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[],["action",4]],[[]],[[],["option",4,[["conflicts",3]]]],[[["stidx",3]],["corereducesiterator",3]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[["action",4]],["bool",15]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[["formatter",3]],["result",6]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[["stidx",3],["ridx",3]],["option",4,[["stidx",3]]]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],[[]],null,[[["action",4]],["bool",15]],[[["yaccgrammar",3],["stategraph",3]],["result",4,[["statetableerror",3]]]],[[],["option",4,[["tidx",3]]]],[[],["option",4,[["pidx",3]]]],null,[[["yaccgrammar",3]],["string",3]],[[["yaccgrammar",3]],["string",3]],[[["yaccgrammar",3]],["string",3]],[[["stidx",3]],["bool",15]],[[]],[[],["usize",15]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[]],[[],["usize",15]],[[],["stidx",3]],[[["stidx",3]],["stateactionsiterator",3]],[[["stidx",3]],["stateactionsiterator",3]],[[]],[[],["string",3]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["result",4]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],[[],["typeid",3]],null,null],"p":[[4,"Minimiser"],[3,"StateGraph"],[3,"StIdx"],[6,"StIdxStorageT"],[4,"Action"],[4,"StateTableErrorKind"],[3,"StateTable"],[3,"StateActionsIterator"],[3,"CoreReducesIterator"],[3,"Conflicts"],[3,"StateTableError"],[13,"Shift"],[13,"Reduce"]]}\
}');
if (window.initSearch) {window.initSearch(searchIndex)};